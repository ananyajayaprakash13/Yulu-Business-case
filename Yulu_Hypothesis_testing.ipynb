{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zqla-fW4rPQf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import binom"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! gdown https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/001/428/original/bike_sharing.csv"
      ],
      "metadata": {
        "id": "DfKdbUimrzyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/bike_sharing.csv')"
      ],
      "metadata": {
        "id": "Uxm2rJyps8es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df.head()"
      ],
      "metadata": {
        "id": "E6g3env6tEMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "ERHKby5utF08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "4lsfEPXstaF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "ul4wbvydtenK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. identifying missing values"
      ],
      "metadata": {
        "id": "lGat3909t9wG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "YQxs4f0stzHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* *there is no missing value in the data set*"
      ],
      "metadata": {
        "id": "ys2lhmzjwWEq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "identifying dublicate values"
      ],
      "metadata": {
        "id": "_Ibb7O39w8uL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "QOhPIrqJuOPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* *there is no dublicate values in the data set*"
      ],
      "metadata": {
        "id": "EJXYVlb7xDDh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "d. Analyzing the distribution of Numerical & Categorical variables."
      ],
      "metadata": {
        "id": "DrzdF74px-mf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of numerical variables\n",
        "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
        "print(\"\\nNumerical columns:\", numerical_cols)\n",
        "\n",
        "df[numerical_cols].hist(bins=15, figsize=(15, 10), layout=(4, 3))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "htG6b2Q3wxzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of categorical variables\n",
        "categorical_cols = df.select_dtypes(exclude=[np.number]).columns\n",
        "print(\"\\nCategorical columns:\", categorical_cols)\n",
        "\n",
        "for col in categorical_cols:\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    sns.countplot(x=col, data=df)\n",
        "    plt.title(f'Distribution of {col}')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "g0TcDwq4xVh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "e. Checking for Outliers and Handling Them Appropriately"
      ],
      "metadata": {
        "id": "9tXIGb2TzRJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in numerical_cols:\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    sns.boxplot(x=df[col])\n",
        "    plt.title(f'Boxplot of {col}')\n",
        "    plt.show()\n",
        "\n",
        "#clipping them to the 1st and 99th percentile\n",
        "for col in numerical_cols:\n",
        "    q1 = df[col].quantile(0.01)\n",
        "    q99 = df[col].quantile(0.99)\n",
        "    df[col] = np.clip(df[col], q1, q99)\n",
        "\n",
        "for col in numerical_cols:\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    sns.boxplot(x=df[col])\n",
        "    plt.title(f'Boxplot of {col} after clipping')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "IXZYPgdsyMd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Establishing Relationship Between Dependent and Independent Variables"
      ],
      "metadata": {
        "id": "5oa9oPw7ztQy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Select only numerical columns\n",
        "numerical_df = df.select_dtypes(include=[np.number])\n",
        "correlation_matrix = numerical_df.corr()\n",
        "\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MoNRNP62z1Bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Checking if theres  any significant difference between the no. of bike rides on Weekdays\n",
        "and Weekends?"
      ],
      "metadata": {
        "id": "0BFFX-9l2OIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_ind\n",
        "\n",
        "df['datetime'] = pd.to_datetime(df['datetime'])\n",
        "\n",
        "\n",
        "df['day_of_week'] = df['datetime'].dt.day_name()\n",
        "\n",
        "\n",
        "df['is_weekend'] = df['day_of_week'].apply(lambda x: 1 if x in ['Saturday', 'Sunday'] else 0)\n",
        "\n",
        "weekday_rentals = df[df['is_weekend'] == 0]['count']\n",
        "weekend_rentals = df[df['is_weekend'] == 1]['count']\n",
        "\n",
        "\n",
        "t_stat, p_value = ttest_ind(weekday_rentals, weekend_rentals)\n",
        "\n",
        "# Set significance level\n",
        "alpha = 0.05\n",
        "\n",
        "print(f\"T-statistic: {t_stat}, P-value: {p_value}\")\n",
        "\n",
        "if p_value <= alpha:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference between the number of bike rides on weekdays and weekends.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant difference between the number of bike rides on weekdays and weekends.\")\n"
      ],
      "metadata": {
        "id": "jFJBT_SB0KDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Demand for Bicycles Based on Weather Conditions"
      ],
      "metadata": {
        "id": "NLZYDCPs2c32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Assuming 'weather' column indicates weather conditions and 'COUNT' indicates the number of rentals\n",
        "weather_conditions = df['weather'].unique()\n",
        "weather_groups = [df[df['weather'] == condition]['count'] for condition in weather_conditions]\n",
        "\n",
        "# One-way ANOVA test\n",
        "f_stat, p_value = f_oneway(*weather_groups)\n",
        "\n",
        "print(f\"F-statistic: {f_stat}, P-value: {p_value}\")\n",
        "\n",
        "if p_value <= alpha:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference in bike rentals across different weather conditions.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant difference in bike rentals across different weather conditions.\")\n"
      ],
      "metadata": {
        "id": "RQhTta5T1Cn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Demand for Bicycles Based on Seasons"
      ],
      "metadata": {
        "id": "OzYfyDBCDfcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "season_conditions = df['season'].unique()\n",
        "season_groups = [df[df['season'] == condition]['count'] for condition in season_conditions]\n",
        "\n",
        "# One-way ANOVA test\n",
        "f_stat, p_value = f_oneway(*season_groups)\n",
        "\n",
        "print(f\"F-statistic: {f_stat}, P-value: {p_value}\")\n",
        "\n",
        "if p_value <= alpha:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference in bike rentals across different seasons.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant difference in bike rentals across different seasons.\")\n"
      ],
      "metadata": {
        "id": "kkUF8xYf2lQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Weather Conditions Across Different Seasons"
      ],
      "metadata": {
        "id": "s_fEQPYgDuPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "contingency_table = pd.crosstab(df['weather'], df['season'])\n",
        "\n",
        "chi2_stat, p_value, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "print(f\"Chi-square statistic: {chi2_stat}, P-value: {p_value}\")\n",
        "\n",
        "if p_value <= alpha:\n",
        "    print(\"Reject the null hypothesis: Weather conditions are significantly different during different seasons.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: Weather conditions are not significantly different during different seasons.\")\n"
      ],
      "metadata": {
        "id": "wfs1Maw5Dpn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Exploratory Data Analysis (EDA)\n",
        "\n",
        "**A. Examine dataset structure, characteristics, and statistical summary.**\n",
        "\n",
        "**Insights**:\n",
        "\n",
        "The dataset contains detailed information on bike rentals, including various attributes such as date, weather, season, and rental counts.\n",
        "The dataset appears to have no missing values or duplicate records, ensuring data quality.\n",
        "\n",
        "**Recommendations**:\n",
        "\n",
        "Continue to ensure data quality by regularly checking for missing values and duplicates. This will help in maintaining accurate and reliable data for future analysis.\n",
        "\n",
        "Implement automated data quality checks in the data pipeline to detect and rectify any anomalies promptly.\n",
        "\n",
        "**B. Identify missing values and perform imputation using an appropriate method.**\n",
        "\n",
        "**Insights**:\n",
        "\n",
        "No missing values were found in the dataset.\n",
        "\n",
        "**Recommendations**:\n",
        "\n",
        "Maintain consistent and complete data entry practices to avoid missing values in future datasets.\n",
        "\n",
        "If missing values do occur, establish a protocol for imputation using appropriate methods to ensure data integrity.\n",
        "\n",
        "**C. Identify and remove duplicate records.**\n",
        "\n",
        "**Insights**:\n",
        " No duplicate records were found in the dataset.\n",
        "\n",
        "**Recommendations**:\n",
        "Implement validation checks to prevent duplicate entries in the system. This ensures the accuracy of usage statistics and demand forecasting.\n",
        "\n",
        "**D. Analyze the distribution of Numerical & Categorical variables**\n",
        "\n",
        "**Insights**:\n",
        "\n",
        "Numerical variables show varying distributions, some of which may be skewed.\n",
        "Categorical variables have different levels of frequency, indicating varied usage patterns.\n",
        "\n",
        "**Recommendations**:\n",
        "\n",
        "* Consider transforming skewed numerical variables to normalize the data. This can improve the performance of predictive models.\n",
        "* For imbalanced categorical variables, consider strategies like targeted marketing or promotions to balance usage across different categories.\n",
        "\n",
        "**e. Check for Outliers and deal with them accordingly.**\n",
        "\n",
        "**Insights**:\n",
        "\n",
        "Outliers were detected and removed based on the IQR method.\n",
        "\n",
        "**Recommendations**:\n",
        "\n",
        "* Investigate the causes of outliers to determine if they indicate data issues or true anomalies. Implement policies to address data entry errors.\n",
        "\n",
        "\n",
        "**Step 2: Establish a Relationship between the Dependent and Independent Variables**\n",
        "\n",
        "**Insights**:\n",
        "\n",
        "The correlation heatmap indicates some highly correlated numerical variables.\n",
        "\n",
        "**Recommendations**:\n",
        "\n",
        "* Remove or combine highly correlated variables to prevent multicollinearity, which can skew the results of predictive models.\n",
        "*  Consider using techniques like Principal Component Analysis (PCA) to reduce the dimensionality of the data while preserving important information.\n",
        "\n",
        "**Step 3: Significant difference between the number of bike rides on Weekdays and Weekends**\n",
        "\n",
        "**Insights**:\n",
        "\n",
        "A significant difference in bike rides between Weekdays and Weekends was found.\n",
        "\n",
        "**Recommendations**:\n",
        "\n",
        "* Increase bike availability during weekends to meet higher demand.\n",
        "* Develop specific marketing strategies for weekdays to boost rentals, such as weekday promotions or partnerships with businesses for commuter benefits.\n",
        "\n",
        "**Step 4: Demand for bicycles on rent for different Weather conditions**\n",
        "\n",
        "**Insights**:\n",
        "\n",
        "The demand for bicycles varies significantly with weather conditions.\n",
        "\n",
        "**Recommendations**:\n",
        "\n",
        "* Adjust the fleet size and maintenance schedules based on weather forecasts to ensure availability during favorable conditions.\n",
        "* Provide weather-appropriate gear (e.g., raincoats, umbrellas) to customers to encourage bike rentals during less favorable weather conditions.\n",
        "\n",
        "**Step 5: Demand for bicycles on rent for different Seasons**\n",
        "\n",
        "**Insights**:\n",
        "\n",
        "The demand for bicycles varies significantly with seasons.\n",
        "\n",
        "***Recommendations***:\n",
        "\n",
        "* Plan for increased maintenance and resource allocation during peak seasons to ensure that the fleet is in optimal condition.\n",
        "*  Launch seasonal marketing campaigns to capitalize on higher demand periods, such as summer or spring.\n",
        "\n",
        "**Step 6: Weather conditions during different Seasons**\n",
        "\n",
        "**Insights**:\n",
        "\n",
        "Weather conditions significantly differ across seasons.\n",
        "\n",
        "*Recommendations*:\n",
        "\n",
        "* Use historical weather patterns to predict bike rental demand and adjust operations accordingly.\n",
        "* Optimize inventory levels based on expected seasonal weather conditions to avoid under- or over-supply of bikes.\n",
        "\n",
        "\n",
        "**SUMMARY AND RECOMMENDATIONS**\n",
        "\n",
        "Based on the analysis, Yulu can enhance its bike-sharing service by implementing the following strategies:\n",
        "\n",
        "* Maintain data quality and consistency to ensure reliable analysis.\n",
        "Address data anomalies and manage outliers to improve the accuracy of\n",
        "insights.\n",
        "* Optimize bike availability and maintenance schedules based on demand patterns influenced by day of the week, weather, and seasons.\n",
        "* Develop targeted marketing campaigns to boost rentals during low-demand periods and capitalize on high-demand times.\n",
        "* Use advanced analytics techniques to manage multicollinearity and dimensionality in the data for better predictive modeling.\n",
        "\n",
        "By leveraging these\n",
        "Insights and Recommendations, Yulu can improve its operational efficiency, customer satisfaction, and overall business performance.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DtEVfa5JKF-O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "                                                               \n",
        "                                                              **THANKYOU**"
      ],
      "metadata": {
        "id": "q5SVupt-StF8"
      }
    }
  ]
}